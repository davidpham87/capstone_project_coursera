trig[udx, list(cond.prob = count/GetBigramCount(s)), by=s]
trig[idx, list(cond.prob = count/GetBigramCount(s)), by=s]
head(trig$count)
head(trig[idx]$count)
trig[idx, list(cond.prob = count/GetBigramCount(s)), by=s]
par(mfrow=C(2,2))
par(mfrow=c(2,2))
plot(1:10)
plot(1:10)
10^1.5
plot(exp(rnorm(1000)))
hist(exp(rnorm(1000)))
curve(dnorm)
curve(dnorm, -2, 2)
curve(function(x) exp(dnorm(x)), -2, 2)
trigram
res
help(grep)
cat(res[, tail(s)])
res2
res23
res2
res2
res2
res
res$s <- gsub('^-', '', res$s)
res
trigram
table(trigram$count)
FreqNGramVecto(trigram)
FreqNGramVector(trigram)
FreqNGramVector(trigram)[order(count)]
table(trigram)
warnings()
ls()
trigram
tri.c
tri.c
tric.[677]
tri.c[677]
is.na(tri.c[677, count])
tri.c
tri.c
adjustedCount(tri.c[0])
adjustedCount(0, tric.c)
adjustedCount(0, tri.c)
adjustedCount(1, tri.c)
tri.c[1]
tri.c[1]
tri.c['1']
idx
n
ratio
DT
DT
DT
DT
DT
DT
tri.c
n
warnings()
DT
DT
DT
DT[,1]
DT[1]
DT[1]$adj.count
DT[1]$adj.count==0
DT
DT$ajd.count
DT$adj.count[1]
DT$adj.count[1]==0
DT[1]
DT
DT
tri.c
DT
DT
DT
DT
DT
DT
DT
unigram
DT
}
GoodTuringSmoothing(DT, v.size)
nrow(unigram)
GoodTuringSmoothing <- function(DT, v.size, alpha = 0.00017){
n <- DT[, sum(inv.freq)]
DT[, adj.count:=0.0]
DT[1, adj.count:=inv.freq/n]
for (i in seq_along(DT$count)[-1]){
if(DT[c(i-1, i), diff(count)!=1]) {
DT[i, adj.count:=(count+alpha)*n/(n+alpha*v.size^2)] # alpha adjustement
} else {
DT[i, adj.count:=(DT[i, count]+1)*(DT[i-1, inv.freq]/DT[i, inv.freq])]
}
return(DT)
}
}
DT.t <- GoodTuringSmoothing(DT, v.size)
DT.t
DT
DT <- tri.c
DT
DT
tri.c
DT <- tri.c
DT
Dt.t
DT.t
n
DT.t
DT
DT
DT.t
tri.c
DT <- data.table(tri.c)
n
DT
DT
DT
DT
DT
v.size
DT
DT.t
DT<- data.table(DT.t)
DT
DT
n
DT
trigram
trigram[J(DT)]
merge(trigram, DT)
DT
DT
DT.res
2954976/17656483675*2
2* 174611/ 2954976
3* 174611/ 2954976
DT
DT.res
trigram
[1] "the, and, that, for, you, with, was, this, have, but, are, not, from, said, they, his, will, all, about, one, has, out, just, who, when, what, more, your, had, like, can, her, their, there, she, would, time, were, some, been, get, its, our, new, them, which, how, now, it's, people, also, good, than, into, first, know, after, day, other, back, over, i'm, because, then, only, him, two, last, make, see, love, year, could, much, going, even, think, way, well, really, years, most, work, don't, too, very, those, still, did, where, before, many, any, want, here, off, great, got, right, these, little, down, while, being, made, through, say, today, home, take, life, may, need, should, things, never, state, week, something, come, around, best, school, another, next, world, three, every, since, why, night, few, always, such, look, game, own, long, city, same, better, big, lot, again, feel, thanks, show, each, use, find, place, that's, both, says, until, family, man, part, help, thing, sure, days, house, put, though, dont, used, end, keep, during, ever, does, team, can't, give, might, high, book, happy, away, getting, season, found, old, went, between, against, let, without, didn't, left, told, thought, play, doing, percent, hope, looking, start, times"
trigram
warnings()
unigram
setkey(unigram, s)
brigram
bigram
head(bigram$s)
head(res)
res
res
nb
ls()
unigram
ngrams
unigram[order(count)]
tail(unigram[order(count)], 100)
x
n
s.
s.
s.
n
unigrams
unigram
unigram[order(count)]
unigram[order(-count)]
head(unigram[order(-count)], 100)
prob.adj$ne
prob.adj$n3
prob.adj$n3['of the']
setkey(prob.adj, 'key.w')
setkeyv(prob.adj, 'key.w')
setkeyv(prob.adj$n3, key.w)
setkeyv(prob.adj$n3, 'key.w')
prob.adj$n3['of the']
prob.adj
prob.adj
prob.adj
prob.adj$n3['of the']
prob.adj$n3
prob.adj$n3['of the']
prob.adj$n3['of the'][cond.prop]
s
s.
s.
res
is.na(NA)
disc.fac
idx
length(s.l)
idx
n-2
length(s.l)
n-21
n-1
idx
idx
idx
n
n
idx
idx
idx
idx
idx
idx
disc.fac
s.
idx
s.
s.
res
s[idx]
s.
res
res
res
res
res[s]
res[,s]
res[,substr(s, ' ')]
res[, strsplit(s, ' ')]
res[, strsplit(s, ' ')][,2]
res[, strsplit(s, ' ')][2,]
t(res[, strsplit(s, ' ')][2,])
rownames(out.res)
rownames(out.res) <- ''
out.res
text.clean
txt.clean
txt.clean[1]
str(txt.clean[1])
head(txt.clean[1]$content)
txt.clean[1]
substring(txt.clean[1]$content, 1, 100)
head(txt.clean[1]$content, 10)
txt.clean
txt.clean[1]
str(txt.clean[1])
txt.clean[1]$content[1]
txt.clean[[1]]
unigram
unigram[-order(-count)]
unigram[order(-count)]
uprob
prog.adj
prob.adj
head(prob.adj$n3)
head(prob.adj$n3, 50)
prob.adj$n3
prob.adj
s
s
out.res
res
out.res
out.res
s
n
PredictNextWord(s, prob.adj)
n
n
n
n
n
n
s.
n
n
res
s.
idx
idx2
idxs
idx
idxs
idxs
s
s.
s.
s.
s.2
s.2
prob.adj$n2
prob.adj$n2['love']
prob.adj$n2
prob.adj$n2['love']
bprob
bprob['love']
prob.adj$n2['love']
prob.adj$n3['love']
prob.adj$n2['love']
uprob
c
s.2
res
prob.adj
prob.adj$n2['love']
prob.adj
prob.adj$n2['love']
idx.l
res
res
out.res
idxs
idx <- idxs[[2]]
s.
res
res
out.res
s
s.l
n
idxs
s.l
s.l
f(idx, s.l)
s.l
idx
idxs
prob.adj
n
n
n
n
n
n
n
n
n
n
n
prob.adj$n3
prob.adj
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
out.res
duplicated(out.res)
out.res
out.res
out.res
prob.adj
prob.adj
out.res
unique(out.res)
install.packages('data.table')
unique(out.res)
data.frame(out.res)
unique(data.frame(out.res))
prob.adj
tables()
prob.adj
ls
ls()
nb <- bigram
ns <- unigram
n<- 2
ns
nb
ns
ns
nb
ns[J(nb)]
bprob
tprob
tprob[c(' ', ''), .I]
tprob[c(' '), .I]
tprob
tprob[c(' '), .I]
tprob[c(' '), -.I]
prob.adj
tprob
head(tprob, 50)
head(tprob, 100)
prob.adj
prob.adj
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
out.l
rbindlist(out.l)
na.omit(rbindlist(out.l))
str(txt.clean)
)
str(txt.clean)
ls()
txt.clean
str(txt.clean)
txt.clean
ls()
gc()
tables()
str(x)

. + > 
. + > 
. + > 
. + > 
. + > 
+ + + > 
. + > 
. + > 
. + > 
. + > 
. + > 
. + > x <- txt.clean[[1]]
str(content)
1000*0.667
1000*0.667/60
warnings()
CountNgramSkip(content[1:200])
CountNgramSkip(content[1:2000])
CountNgramSkip(content[1:2000], 3, 0)
CountNgramSkip(content[1:2000], 3, 0)
443/69
443/60

. + > 
. + > 
. + > system.time(
    res.ngram.skip <- CountNgramSkip(content)
)    user   system  elapsed 
gc()
gc()
tables()
ls()
res2
content[1:108]
cl
res
stopCluster(cl)
bquote({skip <- .(n)})
help(clusterExport)
gc())
gc()
environment(CountNgramSkip)
ls(environment(CountNgramSkip))
emptenv()
emptyenv()
gc())
gc()
ls()
prob.adj
prob.adj.clean
prob.adj.clean$n3
head(prob.adj.clean$n3, 50)
prob.adj.clean
prob.adj
